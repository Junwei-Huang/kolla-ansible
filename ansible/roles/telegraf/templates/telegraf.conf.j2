[global_tags]
[agent]
  interval = "10s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  debug = false
  quiet = false
  hostname = ""
  omit_hostname = false
[[outputs.influxdb]]
  urls = [{% for host in groups['influxdb'] %}"{{ influxdb_proto }}://{{ hostvars[host]['ansible_' + hostvars[host]['api_interface']]['ipv4']['address']}}:{{ influxdb_http_port }}"{% if not loop.last %},{% endif %}{% endfor %}]
  database = "telegraf" # required
  retention_policy = "autogen"
  write_consistency = "any"
  timeout = "5s"
[[inputs.cpu]]
  percpu = true
  totalcpu = true
  fielddrop = ["time_*"]
{% if enable_collectd | bool and inventory_hostname in groups['collectd'] %}
[[inputs.socket_listener]]
  service_address = "udp://{{ hostvars[inventory_hostname]['ansible_' + api_interface]['ipv4']['address'] }}:{{ collectd_udp_port }}"
  name_prefix = "collectd_"
  data_format = "collectd"
  collectd_typesdb = ["/usr/share/collectd/types.db"]
{% endif %}
[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs"]
[[inputs.diskio]]
{% if inventory_hostname in groups['influxdb'] and enable_influxdb | bool %}
[[inputs.influxdb]]
  urls = ["{{ influxdb_proto }}://{{ hostvars[inventory_hostname]['ansible_' + api_interface]['ipv4']['address'] }}:{{ influxdb_http_port }}/debug/vars"]
{% endif %}
[[inputs.kernel]]
[[inputs.mem]]
[[inputs.processes]]
[[inputs.swap]]
[[inputs.system]]
[[inputs.net]]
  interfaces = []
{% if inventory_hostname in groups['haproxy'] and enable_haproxy | bool %}
[[inputs.haproxy]]
  servers = ["{{ haproxy_proto }}://{{ haproxy_user }}:{{ haproxy_password }}@{{ api_interface_address }}:{{ haproxy_stats_port }}"]
{% endif %}
{% if inventory_hostname in groups['memcached'] and enable_memcached | bool %}
[[inputs.memcached]]
  servers = ["{{ api_interface_address }}:{{ memcached_port }}"]
{% endif %}
{% if inventory_hostname in groups['elasticsearch'] and enable_elasticsearch | bool %}
[[inputs.elasticsearch]]
  servers = ["{{ elasticsearch_proto }}://{{ api_interface_address }}:{{ elasticsearch_port }}"]
  local = true
  cluster_health = true
{% endif %}
{% if inventory_hostname in groups['rabbitmq'] and enable_rabbitmq | bool %}
[[inputs.rabbitmq]]
  url = "{{ rabbitmq_proto }}://{{ api_interface_address }}:{{ rabbitmq_management_port }}"
  username = "{{ rabbitmq_user }}"
  password = "{{ rabbitmq_password }}"
{% endif %}
{% if inventory_hostname in groups['outward-rabbitmq'] and enable_outward_rabbitmq | bool %}
[[inputs.rabbitmq]]
  url = "{{ outward_rabbitmq_proto }}://{{ api_interface_address }}:{{ outward_rabbitmq_management_port }}"
  username = "{{ outward_rabbitmq_user }}"
  password = "{{ outward_rabbitmq_password }}"
{% endif %}
{% if inventory_hostname in groups['mariadb'] and enable_mariadb | bool %}
[[inputs.mysql]]
  servers = ["{{ database_user }}:{{ database_password }}@{{ mariadb_proto }}({{ api_interface_address }}:{{ database_port }})/"]
  perf_events_statements_digest_text_limit  = 120
  perf_events_statements_limit              = 250
  perf_events_statements_time_limit         = 86400
  table_schema_databases                    = []
  gather_table_schema                       = true
  gather_process_list                       = true
  gather_info_schema_auto_inc               = true
  gather_slave_status                       = true
  gather_binary_logs                        = true
  gather_table_io_waits                     = true
  gather_table_lock_waits                   = true
  gather_index_io_waits                     = true
  gather_event_waits                        = true
  gather_file_events_stats                  = true
  gather_perf_events_statements             = true
  interval_slow                             = "30m"
{% endif %}
